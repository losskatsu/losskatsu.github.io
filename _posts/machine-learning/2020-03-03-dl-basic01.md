---
title: "[딥러닝] 딥러닝 기초(1) 신경망이란" 
categories:
  - machine-learning
tags:
  - machine-learning
use_math: true
toc: true
toc_label: "My Table of Contents"
toc_icon: "cog"
sidebar:
  title: "AI Machine Learning"
  nav: sidebar-contents
---

# 딥러닝 기초(1) 신경망이란


### 참고링크  

|머신러닝|딥러닝|선형대수|기초통계|최적화|
|:------:|:------:|:------:|:------:|:------:|
|[k-means](https://losskatsu.github.io/machine-learning/kmeans-clustering/)|[신경망이란](https://losskatsu.github.io/machine-learning/dl-basic01/)|[고유값,고유벡터](https://losskatsu.github.io/linear-algebra/eigen/)| [확률변수](https://losskatsu.github.io/statistics/random-variable/) |[컨벡스 셋](https://losskatsu.github.io/machine-learning/convex-set/)|
|[k-최근접이웃](https://losskatsu.github.io/machine-learning/knn/)|[성능함수](https://losskatsu.github.io/machine-learning/dl-basic02/)|[행렬식](https://losskatsu.github.io/linear-algebra/determinant/)| [확률분포](https://losskatsu.github.io/statistics/prob-distribution/) | [컨벡스 함수](https://losskatsu.github.io/machine-learning/convex-function/)|
|[선형회귀](https://losskatsu.github.io/statistics/simple-regression/)|[신경망 학습](https://losskatsu.github.io/machine-learning/dl-basic03/)|[내적](https://losskatsu.github.io/linear-algebra/innerproduct/)| [모집단과 표본](https://losskatsu.github.io/statistics/population-sample/) |[라그랑주 듀얼](https://losskatsu.github.io/machine-learning/dual-function/)|
|[로지스틱회귀](https://losskatsu.github.io/statistics/logistic-regression/) |[교차연결](https://losskatsu.github.io/machine-learning/dl-basic04/) |[기저](https://losskatsu.github.io/linear-algebra/basis/)| [평균과 분산](https://losskatsu.github.io/statistics/mean-vairance/)   | [KKT 조건](https://losskatsu.github.io/machine-learning/kkt/) |
|[릿지,라쏘회귀](https://losskatsu.github.io/machine-learning/l1l2/) |[합성곱 신경망](https://losskatsu.github.io/machine-learning/dl-basic05/) |[랭크, 차원](https://losskatsu.github.io/linear-algebra/rank-dim/)| [공분산, 상관계수](https://losskatsu.github.io/statistics/cov-corr/)  | [ROC 커브](https://losskatsu.github.io/machine-learning/stat-roc-curve/) |
|[의사결정나무](https://losskatsu.github.io/machine-learning/decision-tree/) |[배치, 에포크 차이](https://losskatsu.github.io/machine-learning/epoch-batch/) | [선형변환](https://losskatsu.github.io/linear-algebra/linear-trans/)| [최대가능도추정](https://losskatsu.github.io/statistics/mle/) | [크로스 밸리데이션](https://losskatsu.github.io/machine-learning/cross-validation/) |
|[서포트벡터머신](https://losskatsu.github.io/machine-learning/svm/) | [텐서플로기초(1)](https://losskatsu.github.io/machine-learning/tensorflow-basic01/) |[직교행렬](https://losskatsu.github.io/linear-algebra/orthogonal/) | [베르누이,이항분포](https://losskatsu.github.io/statistics/binomial/)  | [실루엣 스코어](https://losskatsu.github.io/machine-learning/silhouette-score) |
|[원클래스 SVM](https://losskatsu.github.io/machine-learning/oneclass-svm/)  | [텐서플로기초(2)](https://losskatsu.github.io/machine-learning/tensorflow-basic02/)  | [고유값분해](https://losskatsu.github.io/linear-algebra/eigen-decomposition/)| [기하,음이항분포](https://losskatsu.github.io/statistics/geometric-negative/) | |
|[LDA ](https://losskatsu.github.io/machine-learning/lda/) | [seq2seq](https://losskatsu.github.io/machine-learning/seq2seq-keras/) | [특이값분해](https://losskatsu.github.io/linear-algebra/svd/) | [초기하분포](https://losskatsu.github.io/statistics/hypergeometric/) | |
|[GMM](https://losskatsu.github.io/machine-learning/gmm/) | [opencv기초](https://losskatsu.github.io/machine-learning/opencv01) | |[포아송분포](https://losskatsu.github.io/statistics/poisson/) | |
|[부스팅](https://losskatsu.github.io/machine-learning/boosting/) | [resnet](https://losskatsu.github.io/machine-learning/resnet) | | [정규분포](https://losskatsu.github.io/statistics/normaldist/) | |
|[사이킷런 실습](https://losskatsu.github.io/machine-learning/sklearn/) |[다각형내부판별](https://losskatsu.github.io/machine-learning/py-polygon01) | |[감마분포](https://losskatsu.github.io/statistics/gammadist/) | |
| | [엣지판별](https://losskatsu.github.io/machine-learning/edge-detect-canny) | | [지수분포](https://losskatsu.github.io/statistics/exponentialdist/) | |
| | | | [카이제곱분포](https://losskatsu.github.io/statistics/chisquareddist/) | |
| | | | [베타분포](https://losskatsu.github.io/statistics/betadist/) | |
| | | | [균일분포](https://losskatsu.github.io/statistics/uniformdist/) | |


<br/>

<a href="http://www.yes24.com/Product/Goods/97032765" target="_blank"><img src="/assets/images/advertisement/ad-book/ad00001_ml.png" width="800" align="middle">

<br/>



## 딥러닝이란

본 포스팅은 MIT 6.034 Artificial Intelligence 수업을 참고하여 작성하였습니다. 

> 딥러닝(deep learning)은 여러 비선형 변환기법의 조합을 통해 높은 수준의 추상화를 시도하는 머신러닝 알고리즘의 집합으로 정의되며, 큰 틀에서 사람의 사고방식을 컴퓨터에게 가르치는 기계학습의 한 분야라고 이야기 할 수 있다. 

## 딥러닝의 목적

딥러닝에서는 다루는 변수 및 결과 카테고리가 아주 많습니다. 
많게는 수천만개의 변수를 이용해 수천개의 카테고리 중 어느쪽에 속하는지 판별합니다. 
가장 흔하게 쓰는 예제가 개와 고양이를 식별하는 것이죠. 

## 뉴런?

딥러닝을 다루기 앞서 뉴런(neuron)에 대해 이야기 해야할 것 같은데요. 
왜냐하면 딥러닝을 이루고 있는 기초 단위가 뉴런이기 때문입니다. 
뉴런은 실제로 신경계를 구성하는 세포인데요. 
아래 그림 처럼 생겼습니다.

<center><img src="/assets/images/ml/dl/basic_dl/deepbasic01.jpg" width="800"></center>

위 그림에서처럼 뉴런은 다른 뉴런의 축색돌기에서 자신의 수상돌기로 자극을 받아 자신의 축색돌기로 다른 뉴런에게 자극을 전달하는 과정을 거칩니다. 
딥러닝 또한 마찬가지 입니다. 수많은 뉴런들이 자극을 전달 하듯, 
수많은 노드들이 가중치와 함께 서로의 연산결과를 주고 받습니다. 

## 신경망

신경망은 하나 이상의 뉴런의 집합니다. 실제 딥러닝에서 쓰이는 신경망은 아래 그림처럼 생겼는데요. 
$x_1, \dots ,x_n$는 실제로는 저희가 학습시킬 학습데이터 변수이죠. 이미지라고 하면 이미지의 픽셀 rgb값이라고 할 수있습니다. 
이는 위 뉴런 그림에서 자극에 해당한다고 할 수 있죠. 

<center><img src="/assets/images/ml/dl/basic_dl/deepbasic02.jpg" width="800"></center>

위 그림에서 입력값을 전달받은 시그마 박스(?)는 지금까지 입력값의 영향럭을 다 더한다는 것입니다. 
그리고 그 산출값이 임계치를 넘기기에 충분한지 테스트합니다. 
결국 임계치 t를 넘기면 1이됩니다. 

## 그래서 뭘 해야 하나

* ALL or NONE
* 누적된 영향(cumulative influence)
* 시냅틱 가중치(synaptic weight)

위 그림에서 임계치 박스를 보시면 계단함수라는 것을 알 수 있습니다. 
이는 곧 0 또는 1임을 의미하고 이는 ALL or NONE 이라는 뜻입니다. 
한편 임계치 박스 이전의 시그마 박스에는 모든 영향력을 더하는 단계가 있는데요. 
이것은 누적된 영향을 의미합니다. 
그리고 그 이전에는 원본데이터에 가중치를 주는 단계가 있는데요. 
그 때는 가중치를 정하는 것이 매우 중요한 일이 됩니다. 

[2편으로 이동](https://losskatsu.github.io/machine-learning/dl-basic02/)


<br/>

<a href="http://www.yes24.com/Product/Goods/105772247" target="_blank"><img src="/assets/images/advertisement/ad-book/ad00002_la.png" width="800" align="middle">

<br/>

