---
title: "[머신러닝] 파이썬 사이킷런(sklearn) 기초" 
categories:
  - machine-learning
tags:
  - machine-learning
use_math: true
toc: true
toc_label: "My Table of Contents"
toc_icon: "cog"
sidebar:
  title: "AI Machine Learning"
  nav: sidebar-contents
---


# 파이썬(sklearn) 사이킷런(sklearn) 기초

### 참고링크  

|머신러닝|딥러닝|선형대수|기초통계|최적화|
|:------:|:------:|:------:|:------:|:------:|
|[k-means](https://losskatsu.github.io/machine-learning/kmeans-clustering/)|[신경망이란](https://losskatsu.github.io/machine-learning/dl-basic01/)|[고유값,고유벡터](https://losskatsu.github.io/linear-algebra/eigen/)| [확률변수](https://losskatsu.github.io/statistics/random-variable/) |[컨벡스 셋](https://losskatsu.github.io/machine-learning/convex-set/)|
|[k-최근접이웃](https://losskatsu.github.io/machine-learning/knn/)|[성능함수](https://losskatsu.github.io/machine-learning/dl-basic02/)|[행렬식](https://losskatsu.github.io/linear-algebra/determinant/)| [확률분포](https://losskatsu.github.io/statistics/prob-distribution/) | [컨벡스 함수](https://losskatsu.github.io/machine-learning/convex-function/)|
|[선형회귀](https://losskatsu.github.io/statistics/simple-regression/)|[신경망 학습](https://losskatsu.github.io/machine-learning/dl-basic03/)|[내적](https://losskatsu.github.io/linear-algebra/innerproduct/)| [모집단과 표본](https://losskatsu.github.io/statistics/population-sample/) |[라그랑주 듀얼](https://losskatsu.github.io/machine-learning/dual-function/)|
|[로지스틱회귀](https://losskatsu.github.io/statistics/logistic-regression/) |[교차연결](https://losskatsu.github.io/machine-learning/dl-basic04/) |[기저](https://losskatsu.github.io/linear-algebra/basis/)| [평균과 분산](https://losskatsu.github.io/statistics/mean-vairance/)   | [KKT 조건](https://losskatsu.github.io/machine-learning/kkt/) |
|[릿지,라쏘회귀](https://losskatsu.github.io/machine-learning/l1l2/) |[합성곱 신경망](https://losskatsu.github.io/machine-learning/dl-basic05/) |[랭크, 차원](https://losskatsu.github.io/linear-algebra/rank-dim/)| [공분산, 상관계수](https://losskatsu.github.io/statistics/cov-corr/)  | [ROC 커브](https://losskatsu.github.io/machine-learning/stat-roc-curve/) |
|[의사결정나무](https://losskatsu.github.io/machine-learning/decision-tree/) |[배치, 에포크 차이](https://losskatsu.github.io/machine-learning/epoch-batch/) | [선형변환](https://losskatsu.github.io/linear-algebra/linear-trans/)| [최대가능도추정](https://losskatsu.github.io/statistics/mle/) | [크로스 밸리데이션](https://losskatsu.github.io/machine-learning/cross-validation/) |
|[서포트벡터머신](https://losskatsu.github.io/machine-learning/svm/) | [텐서플로기초(1)](https://losskatsu.github.io/machine-learning/tensorflow-basic01/) |[직교행렬](https://losskatsu.github.io/linear-algebra/orthogonal/) | [베르누이,이항분포](https://losskatsu.github.io/statistics/binomial/)  | [실루엣 스코어](https://losskatsu.github.io/machine-learning/silhouette-score) |
|[원클래스 SVM](https://losskatsu.github.io/machine-learning/oneclass-svm/)  | [텐서플로기초(2)](https://losskatsu.github.io/machine-learning/tensorflow-basic02/)  | [고유값분해](https://losskatsu.github.io/linear-algebra/eigen-decomposition/)| [기하,음이항분포](https://losskatsu.github.io/statistics/geometric-negative/) | |
|[LDA ](https://losskatsu.github.io/machine-learning/lda/) | [seq2seq](https://losskatsu.github.io/machine-learning/seq2seq-keras/) | [특이값분해](https://losskatsu.github.io/linear-algebra/svd/) | [초기하분포](https://losskatsu.github.io/statistics/hypergeometric/) | |
|[GMM](https://losskatsu.github.io/machine-learning/gmm/) | [opencv기초](https://losskatsu.github.io/machine-learning/opencv01) | |[포아송분포](https://losskatsu.github.io/statistics/poisson/) | |
|[부스팅](https://losskatsu.github.io/machine-learning/boosting/) | [resnet](https://losskatsu.github.io/machine-learning/resnet) | | [정규분포](https://losskatsu.github.io/statistics/normaldist/) | |
|[사이킷런 실습](https://losskatsu.github.io/machine-learning/sklearn/) |[다각형내부판별](https://losskatsu.github.io/machine-learning/py-polygon01) | |[감마분포](https://losskatsu.github.io/statistics/gammadist/) | |
| | [엣지판별](https://losskatsu.github.io/machine-learning/edge-detect-canny) | | [지수분포](https://losskatsu.github.io/statistics/exponentialdist/) | |
| | | | [카이제곱분포](https://losskatsu.github.io/statistics/chisquareddist/) | |
| | | | [베타분포](https://losskatsu.github.io/statistics/betadist/) | |
| | | | [균일분포](https://losskatsu.github.io/statistics/uniformdist/) | |


<br/>

<a href="http://www.yes24.com/Product/Goods/97032765" target="_blank"><img src="/assets/images/advertisement/ad-book/ad00001_ml.png" width="800" align="middle">

<br/>


## 사이킷런(sklearn)이란?

사이킷런은 파이썬에서 머신러닝 분석을 할 때 유용하게 사용할 수 있는 라이브러리 입니다. 
여러가지 머신러닝 모듈로 구성되어있습니다. 


## 자주 사용되는 모듈을 불러오자

아래 모듈은 자주 사용되는 모듈입니다. 

```python
import numpy as np
import pandas as pd
from sklearn import datasets
# 참고: 분류용 가상 데이터 만들기
from sklearn.datasets import make_classification

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import GaussianNB
from sklearn import svm
from sklearn import tree
from sklearn.ensemble import RandomForestClassifier

import matplotlib.pyplot as plt
```
하나씩 설명을 드리자면

```python
import numpy as np                                       ## 기초 수학 연산 및 행렬계산
import pandas as pd                                      ## 데이터프레임 사용
from sklearn import datasets                             ## iris와 같은 내장 데이터 사용
from sklearn.model_selection import train_test_split     ## train, test 데이터 분할

from sklearn.linear_model import LinearRegression        ## 선형 회귀분석
from sklearn.linear_model import LogisticRegression      ## 로지스틱 회귀분석
from sklearn.naive_bayes import GaussianNB               ## 나이브 베이즈
from sklearn import svm                                  ## 서포트 벡터 머신
from sklearn import tree                                 ## 의사결정나무
from sklearn.ensemble import RandomForestClassifier      ## 랜덤포레스트

import matplotlib.pyplot as plt                          ## plot 그릴때 사용
```

### 가상 데이터 랜덤으로 생성하기

sklean에 내장된 데이터를 사용할 수도 있지만, 직접 만들수도 있습니다. 

```python
# 분류용 가상 데이터 만들기
from sklearn.datasets import make_classification
```
바로 위와같이 make_classification을 이용하면 가상데이터를 만들수 있는데요. 
사용법은 아래와 같습니다. 

```python
X, Y = make_classification(n_samples=1000, n_features=4,
                        n_informative=2, n_redundant=0,
                        random_state=0, suffle=False)
```
make_classification함수는 다음과 같은 옵션들을 제공합니다. 

옵션명 | 설명
-------|---------
n_sample | 표본 수(default=100)
n_features | 독립변수 수(default=20)
n_informative | 종속변수와 상관관계가 존재하는 독립변수 수(default=2)
n_redundant | 독립변수끼리 종속관계에 있는 독립변수 수(default=2)
n_repeated | 중복 독립변수 수(default=0)
n_classes | 종속변수 클래스(라벨) 수(default=2)
n_clusters_per_class | 클래스당 클러스터 수(default=2)
weights | 각 클래스에 할당 된 표본 수
random_state | 난수 생성 시드(seed) 번호

## 데이터 불러오기

### 
저는 사이킷런에 내장되어있는 유방암 데이터를 사용하기로 하겠습니다. 

```python
raw = datasets.load_breast_cancer()         ## sklearn에 내장된 원본 데이터 불러오기
print(raw.feature_names)                    ## 열(column) 이름 확인
['mean radius' 'mean texture' 'mean perimeter' 'mean area'
 'mean smoothness' 'mean compactness' 'mean concavity'
 'mean concave points' 'mean symmetry' 'mean fractal dimension'
 'radius error' 'texture error' 'perimeter error' 'area error'
 'smoothness error' 'compactness error' 'concavity error'
 'concave points error' 'symmetry error' 'fractal dimension error'
 'worst radius' 'worst texture' 'worst perimeter' 'worst area'
 'worst smoothness' 'worst compactness' 'worst concavity'
 'worst concave points' 'worst symmetry' 'worst fractal dimension']

data = pd.DataFrame(raw.data)               ## 독립변수 데이터 모음  
target = pd.DataFrame(raw.target)           ## 종속변수 데이터 모음
rawData = pd.concat([data,target], axis=1)  ## 독립변수 + 종속변수 열 결합

## 열(column)이름 설정
rawData.columns=['mean radius', 'mean texture', 'mean perimeter', 'mean area',
 'mean smoothness', 'mean compactness', 'mean concavity',
 'mean concave points', 'mean symmetry', 'mean fractal dimension',
 'radius error', 'texture error', 'perimeter error', 'area error',
 'smoothness error', 'compactness error', 'concavity error',
 'concave points error', 'symmetry error', 'fractal dimension error',
 'worst radius', 'worst texture', 'worst perimeter', 'worst area',
 'worst smoothness', 'worst compactness', 'worst concavity',
 'worst concave points', 'worst symmetry', 'worst fractal dimension'
 , 'cancer']

rawData.head(10)                                ## 데이터 확인 
```

독립변수 갯수가 너무 많아서 예시로 들기엔 데이터가 크다는 생각이 들었습니다. 
그래서 독립변수는 2개만 사용하도록 하겠습니다.

```python
x = rawData[['mean radius', 'mean texture']]
y = rawData['cancer']
```

## train, test 데이터 분할하기

오버피팅을 막기위해 데이터를 train, test로 분할 합시다. 

```python
x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.25, random_state=0)
```

옵션명 | 설명
-------|--------
test_size | test셋 비율
train_size | train셋 비율(default: 테스트셋의 나머지)
random_state | 랜덤시드번호
suffle | 데이터섞기(default: true)
statify | 라벨 비율 유지


## 사이킷런 제공 api

사이킷런에서는 여러가지 머신러닝 모델을 사용할 수 있는데요.  
대부분의 모델에서 공통적으로 제공되는 api가 있습니다. 

```python
fit(x_train, y_train)     ## 모수 추정(estimat)
get_params()              ## 추정된 모수 확인
predict(x_test)           ## x_test로부터 라벨 예측
predict_log_proba(x_test) ## 로그 취한 확률 예측
predict_proba(x_test)     ## 각 라벨로 예측될 확률
score(x_test, y_test)     ## 모델 정확도 평가를 위한 mean accuracy
```

### mean accuracy란 무엇인가? 

위 api 중 score이라는 함수가 있는데요. 
이 함수는 모델의 성능을 평가하기 위해 mean accuracy를 제공합니다. 
이 때, mean accuracy란 무엇일까요? 
mean accuracy는 각 라벨 종류별로 몇개를 맞췄는지를 나타냅니다. 
예를들어, 유방암 데이터에서 구분되는 라벨은 2가지 입니다. 
병에 걸리지 않았거나(=0), 걸린 경우(=1) 입니다. 
따라서 이 경우 mean accuracy는 아래와 같습니다. 


$ \text{mean accuracy} = (\frac{\text{유방암에 안걸린 사람 맞춘 숫자}}{\text{전체 유방암 안걸린 사람 수}} + \frac{\text{유방암에 걸린 사람 맞춘 숫자}}{\text{전체 유방암 걸린 사람 수}} )\times \frac{1}{2}$  


## 선형회귀분석

```python
clf = LinearRegression()
clf.fit(x_train,y_train)  # 모수 추정
clf.coef_                 # 추정 된 모수 확인(상수항 제외)
clf.intercept_            # 추정 된 상수항 확인
clf.predic(x_test)        # 예측
clf.score(x_test, y_test) # 모형 성능 평가
```

## 로지스틱 회귀분석

```python
clf = LogisticRegression(solver='lbfgs').fit(x_train,y_train)
clf.predict(x_test)
clf.predict_proba(x_test)
clf.score(x_test,y_test)
```

## 나이브 베이즈

```python
gnb = GaussianNB()
gnb.fit(x_train, y_train)
gnb.predict(x_test)
gnb.score(x_test, y_test)
```

## 의사결정 나무

```python
clf = tree.DecisionTreeClassifier()
clf.fit(x_train, y_train)
clf.predict(x_test)
clf.predict_proba(x_test)
clf.score(x_test, y_test)
```

## 서포트벡터머신

```python
clf = svm.SVC(kernel='linear')
clf.fit(x_train, y_train)
clf.predict(x_test)
clf.score(x_test, y_test)
```

## 랜덤포레스트

```python
clf = RandomForestClassifier(max_depth=2, random_state=0)
clf.fit(x_train, y_train)
clf.feature_importances_
clf.predict(x_test)
```


<br/>

<a href="http://www.yes24.com/Product/Goods/105772247" target="_blank"><img src="/assets/images/advertisement/ad-book/ad00002_la.png" width="800" align="middle">

<br/>



