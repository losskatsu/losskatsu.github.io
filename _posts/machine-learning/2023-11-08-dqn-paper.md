---
title: "[딥러닝] Deep Q Network(DQN) 논문 번역" 
categories:
  - machine-learning
tags:
  - machine-learning
use_math: true
toc: true
toc_label: "My Table of Contents"
toc_icon: "cog"
sidebar:
  title: "AI Machine Learning"
  nav: sidebar-contents
---


# Deep Q Network(DQN) 논문 번역

[Playing Atari with Deep Reinforcement Learning](https://www.cs.toronto.edu/~vmnih/docs/dqn.pdf)

## 0. Abstract

우리는 강화학습을 통해서 고차원 센서로부터 직접 정책(policy)을 컨트롤함으로써 성공적으로 딥러닝 모델을 학습시켰다. 
여기서 말하는 딥러닝 모델은 CNN을 의미하는데 이는 Q learning으로 학습 시킨 것이다. 
이러한 모델을 학습 시킬 때 인풋은 각 픽셀(raw pixel)이 되고 아웃풋은 미래 보상에 대한 value function이다. 
우리는 이러한 방법으로 아타리 게임 2600개에 대한 학습 환경으로부터 학습 알고리즘이나 아키텍쳐 변화없이 학습시켰다. 

## 1.Introduction

비전이나 음성 데이터에서 고차원 센서 데이터로부터 나오는 데이터를 에이전트를 컨트롤함으로써 학습시키는 것은 
강화학습 분야에서 오랜 기간동안 도전적인 과제였습니다. 
이러한 도메인에서 가장 성공적인 강화학습 적용은 수작업으로 만든 피처를 linear value function이나 policy representations와 결합시키는 것이었습니다. 
당연하게도 이런 시스템에서의 학습 결과는 feature representation의 퀄리티에 의존적이었습니다. 

최근에와서는 raw 센서 데이터로부터 high-level 피처를 추출하는 것이 가능했고, 이는 컴퓨터 비전이나 음성 인식 분야에서 큰 발전을 이루어냈습니다. 
이러한 방법들은 CNN을 포함하는다양한 신경망 아키텍처를 활용했습니다.





