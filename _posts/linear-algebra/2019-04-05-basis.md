---
title: "[선형대수] 기저(basis)의 의미" 
categories:
  - linear-algebra
tags:
  - statistics
  - machine-learning
use_math: true
toc: true
toc_label: "My Table of Contents"
toc_icon: "cog"
sidebar:
  title: "AI Machine Learning"
  nav: sidebar-contents
---

# 기저(basis)의 의미

### 참고링크  

|머신러닝|딥러닝|선형대수|기초통계|최적화|
|:------:|:------:|:------:|:------:|:------:|
|[k-means](https://losskatsu.github.io/machine-learning/kmeans-clustering/)|[신경망이란](https://losskatsu.github.io/machine-learning/dl-basic01/)|[고유값,고유벡터](https://losskatsu.github.io/linear-algebra/eigen/)| [확률변수](https://losskatsu.github.io/statistics/random-variable/) |[컨벡스 셋](https://losskatsu.github.io/machine-learning/convex-set/)|
|[k-최근접이웃](https://losskatsu.github.io/machine-learning/knn/)|[성능함수](https://losskatsu.github.io/machine-learning/dl-basic02/)|[행렬식](https://losskatsu.github.io/linear-algebra/determinant/)| [확률분포](https://losskatsu.github.io/statistics/prob-distribution/) | [컨벡스 함수](https://losskatsu.github.io/machine-learning/convex-function/)|
|[선형회귀](https://losskatsu.github.io/statistics/simple-regression/)|[신경망 학습](https://losskatsu.github.io/machine-learning/dl-basic03/)|[내적](https://losskatsu.github.io/linear-algebra/innerproduct/)| [모집단과 표본](https://losskatsu.github.io/statistics/population-sample/) |[라그랑주 듀얼](https://losskatsu.github.io/machine-learning/dual-function/)|
|[로지스틱회귀](https://losskatsu.github.io/statistics/logistic-regression/) |[교차연결](https://losskatsu.github.io/machine-learning/dl-basic04/) |[기저](https://losskatsu.github.io/linear-algebra/basis/)| [평균과 분산](https://losskatsu.github.io/statistics/mean-vairance/)   | [KKT 조건](https://losskatsu.github.io/machine-learning/kkt/) |
|[릿지,라쏘회귀](https://losskatsu.github.io/machine-learning/l1l2/) |[합성곱 신경망](https://losskatsu.github.io/machine-learning/dl-basic05/) |[랭크, 차원](https://losskatsu.github.io/linear-algebra/rank-dim/)| [공분산, 상관계수](https://losskatsu.github.io/statistics/cov-corr/)  | [ROC 커브](https://losskatsu.github.io/machine-learning/stat-roc-curve/) |
|[의사결정나무](https://losskatsu.github.io/machine-learning/decision-tree/) |[배치, 에포크 차이](https://losskatsu.github.io/machine-learning/epoch-batch/) | [선형변환](https://losskatsu.github.io/linear-algebra/linear-trans/)| [최대가능도추정](https://losskatsu.github.io/statistics/mle/) | [크로스 밸리데이션](https://losskatsu.github.io/machine-learning/cross-validation/) |
|[서포트벡터머신](https://losskatsu.github.io/machine-learning/svm/) | [텐서플로기초(1)](https://losskatsu.github.io/machine-learning/tensorflow-basic01/) |[직교행렬](https://losskatsu.github.io/linear-algebra/orthogonal/) | [베르누이,이항분포](https://losskatsu.github.io/statistics/binomial/)  | [실루엣 스코어](https://losskatsu.github.io/machine-learning/silhouette-score) |
|[원클래스 SVM](https://losskatsu.github.io/machine-learning/oneclass-svm/)  | [텐서플로기초(2)](https://losskatsu.github.io/machine-learning/tensorflow-basic02/)  | [고유값분해](https://losskatsu.github.io/linear-algebra/eigen-decomposition/)| [기하,음이항분포](https://losskatsu.github.io/statistics/geometric-negative/) | |
|[LDA ](https://losskatsu.github.io/machine-learning/lda/) | [seq2seq](https://losskatsu.github.io/machine-learning/seq2seq-keras/) | [특이값분해](https://losskatsu.github.io/linear-algebra/svd/) | [초기하분포](https://losskatsu.github.io/statistics/hypergeometric/) | |
|[GMM](https://losskatsu.github.io/machine-learning/gmm/) | [opencv기초](https://losskatsu.github.io/machine-learning/opencv01) | |[포아송분포](https://losskatsu.github.io/statistics/poisson/) | |
|[부스팅](https://losskatsu.github.io/machine-learning/boosting/) | [resnet](https://losskatsu.github.io/machine-learning/resnet) | | [정규분포](https://losskatsu.github.io/statistics/normaldist/) | |
|[사이킷런 실습](https://losskatsu.github.io/machine-learning/sklearn/) |[다각형내부판별](https://losskatsu.github.io/machine-learning/py-polygon01) | |[감마분포](https://losskatsu.github.io/statistics/gammadist/) | |
| | [엣지판별](https://losskatsu.github.io/machine-learning/edge-detect-canny) | | [지수분포](https://losskatsu.github.io/statistics/exponentialdist/) | |
| | | | [카이제곱분포](https://losskatsu.github.io/statistics/chisquareddist/) | |
| | | | [베타분포](https://losskatsu.github.io/statistics/betadist/) | |
| | | | [균일분포](https://losskatsu.github.io/statistics/uniformdist/) | |


<br/>

<a href="http://www.yes24.com/Product/Goods/97032765" target="_blank"><img src="/assets/images/advertisement/ad-book/ad00001_ml.png" width="800" align="middle">

<br/>




기저(basis)란 무엇일까요. 
위키백과를 찾아보면 아래와 같은 설명이 나옵니다. 

> 선형대수학에서, 어떤 벡터 공간의 기저(basis)는 그 벡터 공간을 선형생성하는 선형독립인 벡터들이다. 
달리 말해, 벡터 공간의 임의의 벡터에게 선형결합으로서 유일한 표현을 부여하는 벡터들이다. 

지금부터 위 설명이 무엇을 뜻하는지 알아봅시다.

# 1.집 주소에 대한 비유

흔히 자신의 집 주소를 이야기할 때 아래와 같이 말하는 사람이 있다고 가정해 봅시다.

1. 경기도 부천시 무슨동 
2. 수원시 청주시 과천시  

우리는 보통 1과 같이 이야기하지, 2처럼 말하는 사람은 아직까지 한 번도 본적이 없습니다. 
그렇다면 1과 2는 무슨 차이가 있을까요? 
주소 1을 들었을 때는 본인이 지구상에 어디에 위치하는지에 대한 정보를 얻을 수 있습니다. 
반면 주소 2를 들었을 때는 저 사람이 어디에 사는지 알 수 없습니다. 
왜냐면 애초에 수원시와 청주시가 동시에 표현되는 것 자체가 불능이기 때문입니다. 
(주소가 여러 개인 경우는 제외하겠습니다.) 
주소 1을 다시 보시면 경기도와 부천시는 동시에 표현할 수 있습니다. 
왜냐면 '도'라는 기저를 이용해서 표현한 좌표가 경기도이고 '도시'라는 기저를 사용해 나타낸 좌표가 부천시이기 때문입니다. 
따라서 주소 2에서 '도시'라는 기저를 사용해 나타낸 수원시, 과천시의 경우는 말이 안되는 것을 알 수 있습니다. 
왜냐면 어느 한 사람의 주소가 수원시이자 과천시 일 수는 없거든요. 
요약하면 집 주소를 구성하는 기저는 '도', '시', '동'이라고 할 수 있습니다. 
(이해를 돕기 위해, 특별시, 광역시, 구의 개념은 생략했습니다 ^^;)

# 2. 좌표평면에서의 기저

2차원 좌표평면을 생각해봅시다. 이 좌표평면을 구성하는 기저는 무엇일까요?

<center><img src="/assets/images/basis/basis01.JPG" width="800"></center>

좌측, 우측의 벡터쌍을 행렬(matrix)로 표현하면 아래와 같습니다. 

$$ (1) \begin{bmatrix} 1 & 0 \\ 0 & 1 \end{bmatrix},  (2) \begin{bmatrix} 1 & 2 \\ 0 & 0 \end{bmatrix} $$

이 두 행렬은 좌표평면을 나타내는 기저가 될 수 있을까요? 
(1)의 경우는 기저가 될 수 있지만, (2)는 기저가 될 수 없습니다. 
위 그림을 보고 설명 드리자면, 
(1)을 구성하는 벡터조합을 이용하면 좌표평면 내의 모든 점을 나타낼 수 있습니다. 
예를 들어 $(5,3)$이라는 점을 표현하고 싶다면, $5(1,0) + 3(0,1) = (5,3)$으로 표현 가능합니다. 
하지만 (2)를 이용하면 벡터는 두 개지만 표현할 수 있는 건 $x$축이 전부 입니다. 
벡터는 두 개지만 $(2,0)$벡터는 $2(1,0)$처럼 첫번째 벡터로 표현할 수 있으므로, 
실상은 기저벡터가 하나있는 것과 다름 없습니다. 
따라서 (2)를 구성하는 벡터조합을 이용하면 $(5,3)$을 표현할 수 없습니다. 

<center><img src="/assets/images/basis/basis02.JPG" width="800"></center>

# 3. 기저는 유일(unique)한가요?

그렇다면 좌표평면을 구성하는 기저는 아래 행렬이 유일할까요?

$$ \begin{bmatrix} 1 & 0 \\ 0 & 1 \end{bmatrix} $$

그렇지 않습니다. 

$(1,0),(0,1)$ 뿐만 아니라, $(2,0),(0,2)$ 등 $(x,0),(0,y)$ 꼴이라면 모두 기저가 될 수 있습니다. 
하지만 기저를 구성하는 벡터의 수는 유일합니다. 좌표평면을 구성하는 기저벡터는 2개가 입니다. 
이는 차원(dimension)과 관련있는데 이는 다음 포스팅에서 다루겠습니다. 

마지막으로 기저의 정의를 다시 보면서 포스팅 마치겠습니다.

> 선형대수학에서, 어떤 벡터 공간의 기저(basis)는 그 벡터 공간을 선형생성하는 선형독립인 벡터들이다. 
달리 말해, 벡터 공간의 임의의 벡터에게 선형결합으로서 유일한 표현을 부여하는 벡터들이다. 


<br/>

<a href="http://www.yes24.com/Product/Goods/105772247" target="_blank"><img src="/assets/images/advertisement/ad-book/ad00002_la.png" width="800" align="middle">

<br/>
